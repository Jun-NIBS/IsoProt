{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Protocol for analysis of labeled proteomics data\n",
    "We recommend the following structure for describing the protocol and its example workflow. Below you can find an overview of required features of the protocol and its description and rules for best practices.\n",
    "\n",
    "This is the link to the github repository of the protocol \n",
    "TODO add version!\n",
    "https://github.com/ProtProtocols/biocontainer-jupyter\n",
    "\n",
    "Link to docker image:\n",
    "\n",
    "\n",
    "\n",
    "## Abstract\n",
    "Provide a short description of the software protocol including broader context, functionality, use case and purpose. \n",
    "\n",
    "\n",
    "## Maintainer\n",
    "Provide details about the protocol maintainer (e.g. email address and/or github username)\n",
    "\n",
    "## Software\n",
    "Specify links for documentation and tutorials of used software, source code, publications and use cases. Detail versions of each used software. Alternatively, provide links to the software descriptions in https://bio.tools where this information is available.\n",
    "\n",
    "## Diagram\n",
    "Provide a simple diagram of functionality of the workflow/software. We recommend using controlled vocabularies for input/output data types and file formats as well as provided operation of the tool(s). You can use http://edamontology.org terms for the description.\n",
    "\n",
    "__TODO: example__\n",
    "\n",
    "## System requirements\n",
    "Fill in the following items:\n",
    "Required hard disk space for docker image, input and output files: \n",
    "\n",
    "Required memory: \n",
    "\n",
    "Recommmended number of threads: \n",
    "\n",
    "## Example \n",
    "Presentation of well-documented instructions and commands to run the example use case. Depending on the use case and the software, provide link(s) to open the web service incorportated in the Docker image (e.g. 0.0.0.0:8080), bash commands to run programs from the command line and additional code for e.g. checking and visualizing the (intermediate) results. \n",
    "\n",
    "Instead of providing the instructions in this notebook, one can also provide a link to a notebook containing the example use case.\n",
    "\n",
    "## More general use case (optional)\n",
    "Provide link to notebook with a generalized use case that easily can be adapted to e.g. process different input data and concurrent parametrization.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Specify parameters for database search and evaluation of identified peptide-spectrum matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T20:49:08.553035Z",
     "start_time": "2018-03-02T20:49:08.033028Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "hide_input": true,
    "init_cell": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T20:49:10.173444Z",
     "start_time": "2018-03-02T20:49:08.555451Z"
    },
    "code_folding": [
     6,
     100,
     238
    ],
    "hideCode": true,
    "hidePrompt": false,
    "hide_input": true,
    "init_cell": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox, Label\n",
    "import sys, os\n",
    "import subprocess\n",
    "\n",
    "# create an empty class as a storage for all UI widgets\n",
    "class SearchUI:\n",
    "    def __init__(self):\n",
    "        self.work_dir_select = widgets.Dropdown(options={'/data/': '/data/', 'Example files': '/home/biodocker/'}, \n",
    "                                                value='/home/biodocker/')\n",
    "        self.work_dir_select.observe(observe_work_dir_select)\n",
    "        \n",
    "        self.precursor_tolerance = widgets.IntSlider(min=-10,max=30,step=1,value=20)\n",
    "        self.fragment_tolerance = widgets.BoundedFloatText(min=0,max=200,value=0.05)\n",
    "        # TODO: change this to a select box listing all FASTA files in the working directory\n",
    "        self.fasta_db = widgets.Dropdown(options={\"sp_human.fasta\": \"IN/sp_human.fasta\"})\n",
    "        \n",
    "        # TODO  needs table to describe labeling formats\n",
    "        self.labelling = widgets.Dropdown(options=\n",
    "                          {'TMT6': 'TMT 6-plex of K,TMT 6-plex of peptide N-term',\n",
    "                           'TMT10': 'TMT 10-plex of K,TMT 10-plex of peptide N-term','iTRAQ4': 'iTRAQ 4-plex of K,iTRAQ 4-plex of Y,iTRAQ 4-plex of peptide N-term',\n",
    "                           'iTRAQ8 (fixed)': 'iTRAQ 8-plex of K, iTRAQ 8-plex of peptide N-term',\n",
    "                           'iTRAQ8 (variable)': 'iTRAQ 8-plex of Y'},\n",
    "                      value='TMT 10-plex of K,TMT 10-plex of peptide N-term')\n",
    "        \n",
    "        self.missed_cleavages = widgets.IntSlider(min=0,max=10,step=1,value=1)\n",
    "        self.fixed_ptms = widgets.Dropdown(options=[\"Carbamidomethylation of C\",\"None\"])\n",
    "\n",
    "        # PTMs\n",
    "        self.var_ptms = widgets.SelectMultiple(\n",
    "            options=[\"Oxidation of M\",\n",
    "                     \"Phosphorylation of STY\",\n",
    "                     \"Acetylation of peptide N-term\",\n",
    "                     \"Acetylation of protein N-term\"],\n",
    "            value=['Oxidation of M'])\n",
    "        \n",
    "        self.spectra_dir = widgets.Dropdown(options={\"IN\": \"IN\"})\n",
    "\n",
    "        # ww = widgets.Checkbox(description=\"Decoy\")\n",
    "\n",
    "        self.search_button = widgets.Button(\n",
    "            description='Run Search',\n",
    "            disabled=False,\n",
    "            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltip='Launch the search',\n",
    "            icon='check'\n",
    "        )\n",
    "\n",
    "        self.search_button.on_click(run_search)\n",
    "        \n",
    "        \n",
    "    def updateFastaFiles(self, workdir):\n",
    "        # get all FASTA files\n",
    "        fasta_files = [file for file in os.listdir(workdir) if file[-6:] == \".fasta\"]\n",
    "        \n",
    "        # also search all subdirectories for FASTA files\n",
    "        for d in os.listdir(workdir):\n",
    "            d_path = os.path.join(workdir, d)\n",
    "            if os.path.isdir(d_path) and d[0] != \".\":\n",
    "                fasta_files += [os.path.join(d, file) for file in os.listdir(d_path) if file[-6:] == \".fasta\"]\n",
    "        \n",
    "        # create the dict to add as values to the control\n",
    "        file_list = dict()\n",
    "        \n",
    "        for f in fasta_files:\n",
    "            file_list[f] = os.path.join(os.path.abspath(workdir), f)\n",
    "        \n",
    "        self.fasta_db.options = file_list\n",
    "        \n",
    "        # update the list of possible peaklist directories\n",
    "        directories = [d for d in os.listdir(workdir) if os.path.isdir(os.path.join(workdir, d)) and d[0] != \".\"]\n",
    "        \n",
    "        dir_list = dict()\n",
    "        \n",
    "        for d in directories:\n",
    "            dir_list[d] = os.path.join(os.path.abspath(workdir), d)\n",
    "            \n",
    "        self.spectra_dir.options = dir_list\n",
    "        \n",
    "        if \"IN\" in dir_list:\n",
    "            self.spectra_dir.value = dir_list[\"IN\"]\n",
    "        \n",
    "        \n",
    "    def display(self):\n",
    "        self.updateFastaFiles(self.work_dir_select.value)\n",
    "        \n",
    "        settings_box = VBox([Label('Working directory'), self.work_dir_select,\n",
    "                             Label('Precursor tolerance (ppm):'), self.precursor_tolerance, \n",
    "                             Label('Fragment ion tolerance (da):'), self.fragment_tolerance,\n",
    "                             Label('Fasta file (database, must NOT contain decoy sequences):'), self.fasta_db,\n",
    "                             Label('Quantification method:'), self.labelling,\n",
    "                             Label('Number of miscleavages;'), self.missed_cleavages,\n",
    "                             Label('Further fixed modifications'), self.fixed_ptms,\n",
    "                             Label('Further variable modifications (Hold Ctrl to select multiple)'), self.var_ptms,\n",
    "                             Label('Folder for spectra files (files need to be mgf)'), self.spectra_dir,\n",
    "                             self.search_button])\n",
    "\n",
    "        display(settings_box)\n",
    "        \n",
    "\n",
    "def run_search(button):\n",
    "    global searchUI, result_file\n",
    "    \n",
    "    # make sure all required fields were selected\n",
    "    if searchUI.work_dir_select.value is None:\n",
    "        print(\"Error: No working directory selected\")\n",
    "        return\n",
    "    \n",
    "    if searchUI.fasta_db.value is None:\n",
    "        print(\"Error: No FASTA file selected\")\n",
    "        return\n",
    "    \n",
    "    # create the directory paths to work in\n",
    "    peaklist_dir = os.path.abspath(searchUI.spectra_dir.value)\n",
    "    \n",
    "    if not os.path.isdir(peaklist_dir):\n",
    "        raise Exception(\"Invalid peak list directory selected: \" + peaklist_dir + \" does not exist.\")\n",
    "    \n",
    "    peptide_shaker_jar = \"/home/biodocker/bin/PeptideShaker-1.10.3/PeptideShaker-1.10.3.jar\"\n",
    "    work_dir = os.path.abspath(os.path.join(searchUI.work_dir_select.value, \"OUT\"))\n",
    "    \n",
    "    # the searches should be performed in the \"OUT\" directory\n",
    "    if not os.path.isdir(work_dir):\n",
    "        os.mkdir(work_dir)\n",
    "        \n",
    "    print(\"Creating decoy database...\")\n",
    "    \n",
    "    # create the decoy database\n",
    "    subprocess.run([\"java\", \"-cp\", \"/home/biodocker/bin/SearchGUI-2.8.6/SearchGUI-2.8.6.jar\", \n",
    "                   \"eu.isas.searchgui.cmd.FastaCLI\", \"-in\", searchUI.fasta_db.value, \"-decoy\"], check=True,\n",
    "                   cwd=work_dir,\n",
    "                   stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    # get the filename of the decoy database\n",
    "    database_file = searchUI.fasta_db.value[:-6] + \"_concatenated_target_decoy.fasta\"\n",
    "    \n",
    "    if not os.path.isfile(os.path.join(\"OUT\", database_file)):\n",
    "        raise Exception(\"Failed to find generated decoy datbase\")\n",
    "        \n",
    "    # build the arguments to create the parameter file\n",
    "    param_file = os.path.join(work_dir, \"search.par\")\n",
    "    \n",
    "    # remove any old parameters\n",
    "    if os.path.isfile(param_file):\n",
    "        os.remove(param_file)\n",
    "    \n",
    "    search_args = [\"java\", \"-cp\", \"/home/biodocker/bin/SearchGUI-2.8.6/SearchGUI-2.8.6.jar\",\n",
    "                   \"eu.isas.searchgui.cmd.IdentificationParametersCLI\",\n",
    "                   \"-out\", param_file]\n",
    "    \n",
    "    # precursor tolerance\n",
    "    search_args.append(\"-prec_tol\")\n",
    "    search_args.append(str(searchUI.precursor_tolerance.value))\n",
    "    # fragment tolerance\n",
    "    search_args.append(\"-frag_tol\")\n",
    "    search_args.append(str(searchUI.fragment_tolerance.value))\n",
    "    # fixed mods\n",
    "    # TODO: labelling cannot always be set as fixed mod???\n",
    "    fixed_mod_string = str(searchUI.labelling.value) + \",\" + str(searchUI.fixed_ptms.value)\n",
    "    search_args.append(\"-fixed_mods\")\n",
    "    search_args.append(fixed_mod_string)\n",
    "    # database\n",
    "    search_args.append(\"-db\")\n",
    "    search_args.append(database_file)\n",
    "    # missed cleavages\n",
    "    search_args.append(\"-mc\")\n",
    "    search_args.append(str(searchUI.missed_cleavages.value))\n",
    "    \n",
    "    # var mods\n",
    "    if len(searchUI.var_ptms.value) > 0:\n",
    "        search_args.append(\"-variable_mods\")\n",
    "        var_mod_list = list()\n",
    "        \n",
    "        for var_mod in searchUI.var_ptms.value:\n",
    "            if var_mod == \"Phosphorylation of STY\":\n",
    "                var_mod_list += [\"Phosphorylation of S\", \"Phosphorylation of T\", \"Phosphorylation of Y\"]\n",
    "            else:\n",
    "                var_mod_list.append(var_mod)\n",
    "                \n",
    "        search_args.append(\",\".join(var_mod_list))\n",
    "        \n",
    "    # create the search parameter file\n",
    "    print(\"Creating search parameter file...\")\n",
    "    # print(\" \".join(search_args))\n",
    "    subprocess.run(search_args, check=True, cwd=work_dir, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    if not os.path.isfile(param_file):\n",
    "        raise Exception(\"Failed to create search parameters\")\n",
    "        \n",
    "    # run the search\n",
    "    print(\"Running search...\")\n",
    "    # TODO: create list of spectrum files - or the folder\n",
    "    spectrum_files = peaklist_dir\n",
    "    print(\"  Searching files in \" + spectrum_files)\n",
    "    subprocess.run([\"java\", \"-cp\", \"/home/biodocker/bin/SearchGUI-2.8.6/SearchGUI-2.8.6.jar\",\n",
    "                    \"eu.isas.searchgui.cmd.SearchCLI\", \"-spectrum_files\", spectrum_files,\n",
    "                    \"-output_folder\", work_dir, \"-id_params\", param_file,\n",
    "                    \"-xtandem\", \"0\", \"-msgf\", \"1\", \"-comet\", \"0\", \"-ms_amanda\", \"0\", \n",
    "                    \"-myrimatch\", \"0\", \"-andromeda\", \"0\", \"-omssa\", \"0\", \"-tide\", \"0\"],\n",
    "                    check=True, cwd=work_dir, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    print(\"Search completed.\")\n",
    "    \n",
    "    # run PeptideShaker\n",
    "    print(\"Processing result using PeptideShaker...\")\n",
    "    peptide_shaker_result_file = os.path.join(work_dir, \"experiment.cpsx\")\n",
    "\n",
    "    subprocess.run([\"java\", \"-cp\", peptide_shaker_jar,\n",
    "                    \"eu.isas.peptideshaker.cmd.PeptideShakerCLI\",\n",
    "                    \"-experiment\", \"experiment1\",\n",
    "                    \"-sample\", \"test\",\n",
    "                    \"-replicate\", \"1\",\n",
    "                    \"-identification_files\", work_dir,\n",
    "                    \"-out\", peptide_shaker_result_file,\n",
    "                    \"-id_params\", param_file,\n",
    "                    \"-spectrum_files\", spectrum_files],\n",
    "                    check=True, cwd=work_dir, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    if not os.path.isfile(peptide_shaker_result_file):\n",
    "        raise Exception(\"Failed to process result file.\")\n",
    "        \n",
    "    # create TSV output files\n",
    "    print(\"Converting result to TSV format...\")\n",
    "    subprocess.run([\"java\", \"-cp\", peptide_shaker_jar,\n",
    "                  \"eu.isas.peptideshaker.cmd.ReportCLI\",\n",
    "                  \"-in\", peptide_shaker_result_file,\n",
    "                  \"-out_reports\", work_dir,\n",
    "                  \"-reports\", \"8\"],\n",
    "                  check=True, cwd=work_dir, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    result_file=os.path.join(work_dir, \"experiment1_test_1_Extended_PSM_Report.txt\")\n",
    "    \n",
    "    if not os.path.isfile(result_file):\n",
    "        raise Exception(\"Error: Conversion failed\")\n",
    "        \n",
    "    print(\"Done.\")\n",
    "    \n",
    "    \n",
    "def observe_work_dir_select(change):\n",
    "    global work_dir_select\n",
    "    if change['type'] == \"change\" and change['name'] == \"value\":\n",
    "        # update the required UI controls\n",
    "        searchUI.updateFastaFiles(change[\"new\"])\n",
    "\n",
    "# -------------------\n",
    "# Code to create the UI\n",
    "# --------------------\n",
    "result_file=None\n",
    "work_dir=None\n",
    "peaklist_dir=os.path.abspath(\"IN\")\n",
    "\n",
    "searchUI = SearchUI()\n",
    "searchUI.display()\n",
    "\n",
    "#TODO set names of samples and replicates (peptideshaker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%%R -i result_file,peaklist_dir\n",
    "\n",
    "# library causes the execution to fail if the library is missing\n",
    "suppressWarnings(suppressMessages(library(isobar)))\n",
    "\n",
    "# process the input files\n",
    "max.fdr <- 0.01\n",
    "# TODO: set based on python selection\n",
    "quant.method <- \"TMT10plexSpectra\"\n",
    "class.labels <- c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\")\n",
    "args <- commandArgs(trailingOnly = TRUE)\n",
    "\n",
    "ident.file <- result_file\n",
    "mgf.files <- list.files(peaklist_dir, pattern=\"*.mgf$\", full.name=T)\n",
    "\n",
    "if (!file.exists(ident.file)) {\n",
    "    stop(\"Error: Cannot find identification file \", ident.file)\n",
    "}\n",
    "if (length(mgf.files) < 0) {\n",
    "    stop(\"Error: No MGF files found.\")\n",
    "}\n",
    "for (mgf.file in mgf.files) {\n",
    "    if (!file.exists(mgf.file)) {\n",
    "        stop(\"Error: Cannot find MGF file \", mgf.file)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert SearchGUI output to isobar format\n",
    "psms <- read.csv(ident.file, sep = \"\\t\")\n",
    "\n",
    "if (! \"Decoy\" %in% names(psms)) {\n",
    "    stop(\"Error: No decoy information available in output file\")\n",
    "}\n",
    "\n",
    "print(paste(\"Loaded\",nrow(psms), \"PSMs\"))\n",
    "\n",
    "# ---- Confidence filter ----\n",
    "psms <- psms[order(psms[, \"Confidence....\"], decreasing = T), ]\n",
    "decoy.psms <- which(psms[, \"Decoy\"] == \"1\")\n",
    "\n",
    "decoy.count <- 0\n",
    "\n",
    "for (decoy.index in decoy.psms) {\n",
    "    decoy.count <- decoy.count + 1\n",
    "    target.count <- decoy.index - decoy.count\n",
    "\n",
    "    cur.fdr <- (decoy.count * 2) / (decoy.count + target.count)\n",
    "\n",
    "    if (cur.fdr > max.fdr) {\n",
    "        # filter\n",
    "        psms <- psms[1:decoy.index - 1,]\n",
    "        break\n",
    "    }\n",
    "}\n",
    "\n",
    "# print(head(psms))\n",
    "\n",
    "print(paste0(\"Filtered \", nrow(psms), \" PSMs @ \", max.fdr, \" FDR\"))\n",
    "\n",
    "# ---- convert to isobar output ----\n",
    "cols.to.save <- c(\"Protein.s.\", \"Sequence\", \"Spectrum.Title\", \"Variable.Modifications\", \"Confidence....\", \"D.score\", \"Validation\", \"Precursor.m.z.Error..ppm.\", \"Spectrum.File\")\n",
    "\n",
    "if (!all(cols.to.save %in% colnames(psms))) {\n",
    "    stop(\"Error: Unexpected result format\")\n",
    "}\n",
    "\n",
    "psms <- psms[, cols.to.save]\n",
    "colnames(psms) <- c(\"accession\", \"peptide\", \"spectrum\", \"var_mod\", \"pepscore\", \"dscore\", \"validation\", \n",
    "\"precursor.mz.error.ppm\", \"file\")\n",
    "\n",
    "# TODO: add modif...\n",
    "psms$modif <- \"\"\n",
    "\n",
    "write.table(psms, file = \"t.corr.csv\", sep = \"\\t\", row.names = F, quote = F)\n",
    "\n",
    "# ---- isobar workflow ----\n",
    "ib <- readIBSpectra(quant.method, \"t.corr.csv\", mgf.files, decode.titles = T)\n",
    "ib <- correctIsotopeImpurities(ib)\n",
    "ib <- normalize(ib)\n",
    "\n",
    "# Extract peptide and protein ratios\n",
    "noise.model <- NoiseModel(ib)\n",
    "suppressWarnings(protein.ratios <- proteinRatios(ib, noise.model, combn.method = \"versus.channel\", cl = class.labels))\n",
    "suppressWarnings(peptide.ratios <- peptideRatios(ib, noise.model, combn.method = \"versus.channel\", cl = class.labels))\n",
    "\n",
    "boxplot(peptide.ratios$lratio, main = \"Peptide ratios\", ylab = \"Peptide ratio\")\n",
    "boxplot(protein.ratios$lratio, main = \"Protein ratios\", ylab = \"Protein reatios\")\n",
    "\n",
    "# save the ratios for later use\n",
    "saveRDS(protein.ratios, file = \"OUT/protein.ratios.rds\")\n",
    "saveRDS(peptide.ratios, file = \"OUT/peptide.ratios.rds\")"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
