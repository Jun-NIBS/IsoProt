{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# Protocol for analysis of labeled proteomics data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This jupyter notebook contains a complete workflow to process and quantify TMT and iTRAQ labelled MS/MS data.\n",
    "\n",
    "Database searches are performed using [searchGUI](https://github.com/compomics/searchgui) and the subsequent search results are filtered using [PeptideShaker](https://github.com/compomics/peptide-shaker).\n",
    "\n",
    "This pipeline currently only supports experimental setups where **each channel represents one sample**. It is currently not possible to merge results from different \n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Convert raw MS data to MGF files (PeptideShaker currently requires all input files to be in the MGF format). We recommend [ProteoWizard](http://proteowizard.sourceforge.net/).\n",
    "\n",
    "2. Use the \"Home\" screen of the Jupyter environment (normally at http://0.0.0.0:8888/tree?), navigate to the `IN` directory and copy all MGF files there (using the `Upload` button)\n",
    "\n",
    "3. Scroll down in this document until you reach the `Workflow` section to start processing your data.\n",
    "\n",
    "\n",
    "## Maintainer\n",
    "\n",
    "  * Veit Schwammle (veits@bmb.sdu.dk)\n",
    "  * Johannes Griss (johannes.griss@meduniwien.ac.at)\n",
    "\n",
    "## Software\n",
    "\n",
    "Specify links for documentation and tutorials of used software, source code, publications and use cases. Detail versions of each used software. Alternatively, provide links to the software descriptions in https://bio.tools where this information is available.\n",
    "\n",
    "## Diagram\n",
    "\n",
    "Provide a simple diagram of functionality of the workflow/software. We recommend using controlled vocabularies for input/output data types and file formats as well as provided operation of the tool(s). You can use http://edamontology.org terms for the description.\n",
    "\n",
    "__TODO: example__\n",
    "\n",
    "## System requirements\n",
    "\n",
    "Fill in the following items:\n",
    "Required hard disk space for docker image, input and output files: \n",
    "\n",
    "Required memory: \n",
    "\n",
    "Recommmended number of threads: \n",
    "\n",
    "## Example \n",
    "\n",
    "Presentation of well-documented instructions and commands to run the example use case. Depending on the use case and the software, provide link(s) to open the web service incorportated in the Docker image (e.g. 0.0.0.0:8080), bash commands to run programs from the command line and additional code for e.g. checking and visualizing the (intermediate) results. \n",
    "\n",
    "The example data file is an extract of spectra from the iTRAQ 8-plex data in ref. https://doi.org/10.1371/journal.pone.0137048\n",
    "\n",
    "\n",
    "Instead of providing the instructions in this notebook, one can also provide a link to a notebook containing the example use case.\n",
    "\n",
    "## More general use case (optional)\n",
    "Provide link to notebook with a generalized use case that easily can be adapted to e.g. process different input data and concurrent parametrization.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# Workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T15:00:57.427705Z",
     "start_time": "2018-06-06T15:00:56.967629Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "hide_input": true,
    "init_cell": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "Specify parameters for database search and evaluation of identified peptide-spectrum matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T15:01:00.223789Z",
     "start_time": "2018-06-06T15:00:57.429731Z"
    },
    "code_folding": [],
    "hideCode": true,
    "hidePrompt": true,
    "hide_input": true,
    "init_cell": true,
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This cell contains the complete code to\n",
    "# 1.) Display the GUI for the user to enter the search parameters\n",
    "# 2.) Launch the search based on these parameters\n",
    "# 3.) Display a button once the search is complete to execute the subsequent R analysis code\n",
    "\n",
    "search_in = None\n",
    "\n",
    "def complete_function():\n",
    "    global search_in\n",
    "    \n",
    "    search_in = search_ui_out\n",
    "    search_in[\"on_search_complete\"] = search_complete\n",
    "    %run \"Scripts/search.ipy\"\n",
    "    \n",
    "def search_complete():\n",
    "    # Display a button to execute the next R cell(s)\n",
    "    btn_next_cell_in = {\"description\": \"Run analysis\", \"n_cells_to_run\": 1}\n",
    "    %run \"Scripts/btn_next_cell.ipy\"\n",
    "\n",
    "search_ui_in = {\"on_complete_description\": \"Run my search\", \"on_complete_function\": complete_function}\n",
    "\n",
    "%run \"Scripts/search_ui.ipy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Search Settings into R Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:04:53.158136Z",
     "start_time": "2018-06-06T16:04:53.152559Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# Since py2ri cannot convert dict objects, simply save everything R needs as a JSON string\n",
    "\n",
    "# remove the callback function first\n",
    "search_in.pop(\"on_search_complete\", None)\n",
    "\n",
    "import json\n",
    "search_in_string = json.dumps(search_in)\n",
    "search_out_string = json.dumps(search_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:04:55.200830Z",
     "start_time": "2018-06-06T16:04:55.114398Z"
    },
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "%%R -i search_in_string,search_out_string\n",
    "# Convert the JSON objects back into \"natural\" R objects\n",
    "suppressWarnings(library(rjson))\n",
    "\n",
    "search_in = fromJSON(search_in_string, simplify = T)\n",
    "search_out = fromJSON(search_out_string, simplify = T)\n",
    "\n",
    "rm(search_in_string, search_out_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:04:57.396228Z",
     "start_time": "2018-06-06T16:04:57.375553Z"
    }
   },
   "outputs": [],
   "source": [
    "search_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Quantify Spectra at the peptide level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T18:06:45.391251Z",
     "start_time": "2018-06-06T18:06:31.532579Z"
    },
    "code_folding": [
     74
    ],
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%R --width=1000\n",
    "\n",
    "## assuming that the computer allows min. 4 threads\n",
    "NumThreads <- 4\n",
    "\n",
    "# library causes the execution to fail if the library is missing\n",
    "suppressWarnings(suppressMessages(library(lattice)))\n",
    "suppressWarnings(suppressMessages(library(stringr)))\n",
    "suppressWarnings(suppressMessages(library(mzID)))\n",
    "suppressWarnings(suppressMessages(library(MSnbase)))\n",
    "\n",
    "# warnings as stdout\n",
    "sink(stdout(), type = \"message\")\n",
    "\n",
    "# change to the input directory\n",
    "setwd(search_in[\"input_directory\"][[1]])\n",
    "\n",
    "## Folder names for different runs (e.g. different replicates, ...)\n",
    "samples <- s <- c(\".\")\n",
    "PSMDat <- PepDat <- ProtDat <- list()\n",
    "for (s in samples) {\n",
    "    ## Organize technical runs in the same folder\n",
    "    # filenames\n",
    "    ident_files <- list.files(paste(\"/home/biodocker/OUT/\",s,sep=\"\"),\n",
    "                              pattern=\"Extended_PSM_Report.txt$\",full.names=T)\n",
    "    mgf_files <- list.files(s,pattern=\"mgf.filtered$\",full.names = T)\n",
    "  \n",
    "    # make sure all input files exist\n",
    "    if (is.null(ident_files)) {\n",
    "        stop(\"Error: No identification files\")\n",
    "    }\n",
    "    if (is.null(mgf_files)) {\n",
    "        stop(\"Error: No spectrum files\")\n",
    "    }\n",
    "    if (!file.exists(ident_files)) {\n",
    "        stop(\"Error: Cannot find identification files \", ident_files)\n",
    "    }\n",
    "    for (mgf_file in mgf_files) {\n",
    "        if (!file.exists(mgf_file)) {\n",
    "            stop(\"Error: Cannot find mgf file \", mgf_file)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # ---- load the PSMs ----\n",
    "    max.fdr <- search_in[\"target_fdr\"]\n",
    "    psms <- read.csv(ident_files, sep = \"\\t\",stringsAsFactors = F)\n",
    "  \n",
    "    if (! \"Decoy\" %in% names(psms)) {\n",
    "        stop(\"Error: No decoy information available in output file\")\n",
    "    }\n",
    "  \n",
    "    print(paste(\"Loaded\",nrow(psms), \"PSMs\"))\n",
    "  \n",
    "    # ---- Confidence filter ----\n",
    "    # TODO: This could be replaced by the PeptideShaker functionality\n",
    "    psms <- psms[order(psms[, \"Confidence....\"], decreasing = T), ]\n",
    "    decoy.psms <- which(psms[, \"Decoy\"] == \"1\")\n",
    "  \n",
    "    decoy.count <- 0\n",
    "  \n",
    "    for (decoy.index in decoy.psms) {\n",
    "        decoy.count <- decoy.count + 1\n",
    "        target.count <- decoy.index - decoy.count\n",
    "        cur.fdr <- (decoy.count * 2) / (decoy.count + target.count)\n",
    "    \n",
    "        if (cur.fdr > max.fdr) {\n",
    "          # filter\n",
    "          psms <- psms[1:decoy.index - 1,]\n",
    "          break\n",
    "        }\n",
    "    }\n",
    "  \n",
    "    print(paste0(\"Filtered \", nrow(psms), \" PSMs @ \", max.fdr, \" FDR\"))\n",
    "    \n",
    "    if (nrow(psms) < 1) {\n",
    "        stop(\"Error: No valid PSMs found\")\n",
    "    }\n",
    "    \n",
    "    # ---- prepare for MSnbase ----\n",
    "    psms$rank <- 1\n",
    "    psms$desc <- psms$Protein.s.\n",
    "    psms$spectrumID <- psms$Spectrum.Title #str_extract(psms$Spectrum.Title, \"scan=[0-9]*\")\n",
    "    psms$spectrumFile <- psms$Spectrum.File\n",
    "    psms$idFile <- ident_files\n",
    "    # remove unnecessary PTMs from modified sequence\n",
    "    # TODO: define whether to take oxidation, ...\n",
    "    psms$Modified.Sequence <- gsub(\"<cmm>\",\"\",psms$Modified.Sequence)\n",
    "    psms$Modified.Sequence <- sub(\"[a-z,A-Z]*-\",\"\",psms$Modified.Sequence)\n",
    "    psms$Modified.Sequence <- sub(\"-[a-z,A-Z]*\",\"\",psms$Modified.Sequence)\n",
    "    psms$Modified.Sequence <- gsub(\"<iTRAQ>\",\"\",psms$Modified.Sequence)\n",
    "    psms$Modified.Sequence <- gsub(\"<TMT>\",\"\",psms$Modified.Sequence)\n",
    "    psms$sequence <- psms$Modified.Sequence\n",
    "    # Optional:\n",
    "    # psms$Modified.Sequence <- gsub(\"<ox>\",\"\",psms$Modified.Sequence)\n",
    "  \n",
    "    # --- Load the spectra ----\n",
    "    allSpectra <- list()\n",
    "    for (mgf_file in mgf_files) {\n",
    "        myExp1 <- readMgfData(mgf_file, verbose=T)\n",
    "    \n",
    "        for (i in 1:ncol(fData(myExp1))) {\n",
    "          if (is.factor(fData(myExp1)[,i]))\n",
    "            fData(myExp1)[,i] <- as.character(fData(myExp1)[,i])\n",
    "        }\n",
    "        fData(myExp1)$spectrumFile <- mgf_file\n",
    "        allSpectra[[mgf_file]] <- myExp1\n",
    "    }\n",
    "    \n",
    "    # ---- merge identification and spectra data and run the quantification ----\n",
    "    # get the MSnbase quantification object\n",
    "    known.methods <- c(\"TMT10\",\"TMT6\",\"iTRAQ4\",\"iTRAQ8\",\"iTRAQ4\", \"iTRAQ8\")\n",
    "    \n",
    "    if (!search_in[\"labelling_method\"][[1]] %in% known.methods) {\n",
    "        stop(\"Error: Labelling method not supported\")\n",
    "    }\n",
    "    \n",
    "    quant.method <- get(search_in[\"labelling_method\"][[1]])\n",
    "    \n",
    "    # run the merging and quantification in paralell\n",
    "    cl <- makeCluster(NumThreads)\n",
    "    myExp <- qnt <- list()\n",
    "    for (mgf_file in mgf_files) {\n",
    "        myExp[[mgf_file]] <- addIdentificationData(\n",
    "            allSpectra[[mgf_file]],\n",
    "            psms,\n",
    "            decoy=\"Decoy\",\n",
    "            rank=\"rank\",\n",
    "            acc=\"Protein.s.\",\n",
    "            icol=\"Spectrum.Title\",\n",
    "            fcol=\"TITLE\",\n",
    "            desc=\"desc\",\n",
    "            pepseq=\"Modified.Sequence\",\n",
    "            verbose=T)\n",
    "        # print(idSummary(myExp[[mgf_file]]))\n",
    "        \n",
    "        # remove all unidentified spectra\n",
    "        myExp[[mgf_file]] <- removeNoId(myExp[[mgf_file]])\n",
    "        \n",
    "        # quantify everything\n",
    "        qnt[[mgf_file]] <- quantify(myExp[[mgf_file]], \n",
    "                                    method = \"sum\", \n",
    "                                    reporters = quant.method, \n",
    "                                    strict = F, verbose = T )\n",
    "      \n",
    "        # Plot reporter QC\n",
    "        hist(unlist(mz(myExp[[mgf_file]])), 1000, main=paste(\"m/z accuracy of reporter ions\\n\",mgf_file), \n",
    "            xlim=range(quant.method@mz)+c(-1,1),xlab=\"m/z\",col=\"#666666\",border=NA)\n",
    "        abline(v=quant.method@mz,col=2,lwd=0.5)\n",
    "    } \n",
    "    \n",
    "    stopCluster(cl)\n",
    "    \n",
    "    # ---- run the impurity correction ----\n",
    "    imp <- makeImpuritiesMatrix(length(quant.method),edit=F)\n",
    "    for (i in 1:length(qnt)) {\n",
    "        qnt[[i]] <- purityCorrect(qnt[[i]],imp)\n",
    "        exprs(qnt[[i]]) <- log2(exprs(qnt[[i]]))\n",
    "        qnt[[i]] <- normalise(qnt[[i]],\"center.median\")\n",
    "        qnt[[i]] <- updateFeatureNames(qnt[[i]],label = paste(\"Sample\",i))\n",
    "    }\n",
    "    \n",
    "    # ---- combine the quantification data ----\n",
    "    names(qnt) <- NULL\n",
    "    allqnt <- do.call(\"combine\",args=qnt)\n",
    "    allqnt <- filterNA(allqnt, pNA=0.5)\n",
    "\n",
    "    # ---- add the sample annotations ----\n",
    "    # load experimental design description    \n",
    "    exp.design <- read.csv(search_in[\"exp_design_file\"][[1]], sep = \"\\t\")\n",
    "    \n",
    "    if (nrow(exp.design) != nrow(pData(allqnt))) {\n",
    "        stop(\"Error: Experimental design does not fit the number of quantified ions.\")\n",
    "    }\n",
    "\n",
    "    # merge the annotations\n",
    "    pdata.org <- pData(allqnt)\n",
    "    pdata.combined <- merge(pdata.org, exp.design, all.x = T, all.y = F, by.x = 0, by.y = \"channel\")\n",
    "    rownames(pdata.combined) <- pdata.combined[, \"Row.names\"]\n",
    "    pdata.combined$Row.names <- NULL\n",
    "\n",
    "    # save\n",
    "    pData(allqnt) <- pdata.combined[colnames(allqnt), ]\n",
    "  \n",
    "    ## Setting the stage for the iPQF inference method\n",
    "    names(fData(allqnt))[which(names(fData(allqnt))==\"Protein.s.\")] <- \"accession\"\n",
    "    names(fData(allqnt))[which(names(fData(allqnt))==\"Variable.Modifications\")] <- \"modifications\"\n",
    "    names(fData(allqnt))[which(names(fData(allqnt))==\"m.z\")] <- \"mass_to_charge\"\n",
    "    names(fData(allqnt))[which(names(fData(allqnt))==\"Confidence....\")] <- \"search_engine_score\"\n",
    "    \n",
    "    write.csv(exprs(allqnt),paste(\"/home/biodocker/OUT/\",s,\"/AllQuantPSMs.csv\",sep=\"\"))  \n",
    "    save(allqnt, file=paste(\"/home/biodocker/OUT/\",s,\"/AllQuantPSMs.RData\",sep=\"\") )\n",
    "    \n",
    "    PSMDat[[s]] <- allqnt \n",
    "}    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T18:38:24.037302Z",
     "start_time": "2018-05-16T18:38:24.029250Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%%R --width 800 --height 800\n",
    "\n",
    "\n",
    "library(plotly)\n",
    "library(reshape)\n",
    "\n",
    "\n",
    "# TODO read experimental design\n",
    "ExpDesign <- read.table(\"/home/biodocker/OUT/exp_design.tsv\")\n",
    "\n",
    "\n",
    "panel.cor <- function(x, y, digits=2, prefix=\"\", cex.cor, ...) \n",
    "{\n",
    "    usr <- par(\"usr\"); on.exit(par(usr)) \n",
    "    par(usr = c(0, 1, 0, 1)) \n",
    "    r <- abs(cor(x, y, use=\"na.or.complete\")) \n",
    "    txt <- format(c(r, 0.123456789), digits=digits)[1] \n",
    "    txt <- paste(prefix, txt, sep=\"\") \n",
    "    cex.cor <- 0.8/strwidth(txt) \n",
    "    test <- cor.test(x,y) \n",
    "    # borrowed from printCoefmat\n",
    "    Signif <- symnum(test$p.value, corr = FALSE, na = FALSE, \n",
    "                  cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),\n",
    "                  symbols = c(\"***\", \"**\", \"*\", \".\", \" \")) \n",
    " \n",
    "    text(0.5, 0.5, txt, cex = cex.cor * r) \n",
    "   # text(.8, .8, Signif, cex=cex.cor, col=2) \n",
    "}\n",
    "\n",
    "panel.hist <- function(x, hist.col=\"#993333\", ...)\n",
    "{\n",
    "    usr <- par(\"usr\"); on.exit(par(usr))\n",
    "   par(usr = c(usr[1:2], 0, 1.5) )\n",
    "    h <- hist(x, plot = FALSE, border=NA,breaks=50)\n",
    "    breaks <- h$breaks; nB <- length(breaks)\n",
    "  y <- h$counts; y <- y/max(y)\n",
    "    rect(breaks[-nB], 0, breaks[-1], y,col=hist.col,border=NA)\n",
    "}\n",
    "\n",
    "for (s in samples) {\n",
    "    allqnt <- PSMDat[[s]]\n",
    "    \n",
    "    condNames <- ExpDesign[ExpDesign[,2] == unique(ExpDesign[,2])[which(s==samples)],1]\n",
    "    conditions <- condNames\n",
    "    condNames <- paste(condNames, sampleNames(allqnt), sep=\"\\n\")\n",
    "    pData(allqnt)$sample_name <- paste(condNames, sampleNames(allqnt))\n",
    "pData(allqnt)$sample_group <- condNames\n",
    "    \n",
    "    \n",
    "    #print(pData(allqnt))\n",
    "    \n",
    "    ## QC Plots\n",
    "  #boxplot(exprs(allqnt), main =paste(\"Sample\",s), labels =  condNames)\n",
    "    \n",
    "       conditionsPlot <- rep(conditions, each=nrow(exprs(allqnt)))\n",
    "    p <- ggplot(melt(exprs(allqnt)), aes(x=X2, y=value, fill=conditionsPlot)) + geom_violin(trim=FALSE) + \n",
    "  geom_boxplot(width=0.1) + theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n",
    "    xlab(\"\") + ylab(\"PSM expression\")\n",
    "\n",
    "print(p)\n",
    "        \n",
    "  pairs(exprs(allqnt),lower.panel=panel.smooth, upper.panel=panel.cor, diag.panel=panel.hist, main = paste(\"Sample\",s),\n",
    "cex=0.1,col=\"#33333388\",pch=15, labels =  condNames)\n",
    "    \n",
    "  #print(fData(allqnt))  \n",
    "}\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T18:38:24.086733Z",
     "start_time": "2018-05-16T18:38:24.039772Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%%R --width 800 --height 800\n",
    "\n",
    "print(\"PSM filtering and impurity correction\")\n",
    "\n",
    "for (s in samples) {\n",
    "    allqnt <- PSMDat[[s]]\n",
    "\n",
    "imp<-makeImpuritiesMatrix(length(quant.method),edit=F)\n",
    "  for (i in 1:length(qnt)) {\n",
    "    qnt[[i]] <- purityCorrect(qnt[[i]],imp)\n",
    "    exprs(qnt[[i]]) <- log2(exprs(qnt[[i]]))\n",
    "    qnt[[i]] <- normalise(qnt[[i]],\"center.median\")\n",
    "    qnt[[i]] <- updateFeatureNames(qnt[[i]],label = paste(\"Sample\",i))\n",
    "  }\n",
    "      \n",
    "  names(qnt) <- NULL\n",
    "  allqnt <- do.call(\"combine\",args=qnt)\n",
    "      \n",
    "  allqnt <- filterNA(allqnt, pNA=0.5)\n",
    "\n",
    "\n",
    "  ## Setting the stage for the iPQF inference method\n",
    "  names(fData(allqnt))[which(names(fData(allqnt))==\"Protein.s.\")] <- \"accession\"\n",
    "  names(fData(allqnt))[which(names(fData(allqnt))==\"Variable.Modifications\")] <- \"modifications\"\n",
    "  names(fData(allqnt))[which(names(fData(allqnt))==\"m.z\")] <- \"mass_to_charge\"\n",
    "  names(fData(allqnt))[which(names(fData(allqnt))==\"Confidence....\")] <- \"search_engine_score\"\n",
    "    head(allqnt)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T18:38:24.118763Z",
     "start_time": "2018-05-16T18:38:24.089131Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%%R --width 800 --height 800\n",
    "\n",
    "print(\"Protein inference ...\")    \n",
    "\n",
    "for (s in samples) {\n",
    "\n",
    "    load(paste(\"/home/biodocker/OUT/\",s,\"/AllQuantPSMs.RData\",sep=\"\"))\n",
    "exprs(allqnt) <- 2^exprs(allqnt)\n",
    "\n",
    "print(paste(\"Sample\",s))\n",
    "    \n",
    "    \n",
    "  #Problem: iPQF does not seem to work with missing values!\n",
    "  allProts <- combineFeatures(allqnt, groupBy=fData(allqnt)$accession, fun=\"medpolish\",verbose=F, na.rm=T)\n",
    " exprs(allProts) <- log2(exprs(allProts))\n",
    "   \n",
    "    \n",
    "  #print(head(melt(exprs(allProts))))\n",
    "    \n",
    "  #boxplot(exprs(allProts\n",
    "    \n",
    "    p <- ggplot(melt(exprs(allProts)), aes(x=X2, y=value, fill=rep(conditions,each=nrow(exprs(allProts))))) + geom_violin(trim=FALSE) + \n",
    "  geom_boxplot(width=0.1) + theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n",
    "    xlab(\"\") + ylab(\"Protein expression\")\n",
    "\n",
    "print(p)\n",
    "\n",
    "    \n",
    "  #stop(\"\")\n",
    "  #pairs(exprs(allProts))\n",
    "  #save\n",
    "  write.exprs(allProts,file=paste(\"/home/biodocker/OUT/\",s,\"/AllQuantProteins.csv\",sep=\"\"))\n",
    "  \n",
    "  ProtDat[[s]] <- allProts <- exprs(allProts)\n",
    "    colnames(ProtDat[[s]]) <- condNames\n",
    "  \n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T18:38:24.137555Z",
     "start_time": "2018-05-16T18:38:24.121324Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%%R --width 1000 --height 600\n",
    "\n",
    "print(\"Merging samples (if needed) ...\")\n",
    "\n",
    "par(mfrow=c(1,1))\n",
    "\n",
    "\n",
    "# Merge different samples\n",
    "    totProts <- ProtDat[[1]]\n",
    "if (length(samples)>1) {\n",
    "    for (s in samples[2:length(samples)])\n",
    "    totProts <- merge(totProts,ProtDat[[s]], all=T, by.x=1, by.y=0)\n",
    "} \n",
    "\n",
    "write.csv(totProts,file=paste(\"/home/biodocker/OUT/AllQuantProteinsInAllSamples.csv\",sep=\"\"))\n",
    "\n",
    "# PCA\n",
    "  pca <- princomp(totProts[complete.cases((totProts)),])\n",
    "  #plot(pca)\n",
    "  plot(pca$loadings, cex=2, pch=16, col=as.numeric(as.factor(ExpDesign[,1])))\n",
    "  text(pca$loadings,colnames(totProts), pos=2)\n",
    "    \n",
    "  print(paste(\"Quantified a total of\",nrow(allProts),\"protein groups\"))\n",
    "\n",
    "\n",
    "\n",
    "##Statistics\n",
    "library(limma)\n",
    "library(qvalue)\n",
    "NumCond <- length(unique(ExpDesign[,1]))\n",
    "  if (NumCond < 2)\n",
    "      stop(\"Only 1 experimental condition -> no statistics\")\n",
    "\n",
    "design <- model.matrix(~0+factor(ExpDesign[,1])-1)\n",
    "  colnames(design)<-paste(unique(ExpDesign[,1]),i,sep=\"\")\n",
    "  contrasts<-NULL\n",
    "  First <- 1\n",
    "  for (i in (1:NumCond)[-First]) contrasts<-append(contrasts,paste(colnames(design)[i],\"-\",colnames(design)[First],sep=\"\"))\n",
    "  contrast.matrix<-makeContrasts(contrasts=contrasts,levels=design)\n",
    "  # print(dim(Data))\n",
    "  lm.fitted <- lmFit(totProts,design)\n",
    "  lm.contr <- contrasts.fit(lm.fitted,contrast.matrix)\n",
    "  lm.bayes<-eBayes(lm.contr)\n",
    "  topTable(lm.bayes)\n",
    " plvalues <- lm.bayes$p.value\n",
    "fcs <- lm.bayes$coefficients\n",
    "  qlvalues <- matrix(NA,nrow=nrow(plvalues),ncol=ncol(plvalues),dimnames=dimnames(plvalues))\n",
    "  # qvalue correction\n",
    " for (i in 1:ncol(plvalues)) {\n",
    "    tqs <- qvalue(na.omit(plvalues[,i]))$qvalues\n",
    "    qlvalues[names(tqs),i] <- tqs\n",
    "  }\n",
    "  \n",
    "\n",
    "par(mfrow=c(1,3))\n",
    "\n",
    "statTable <- NULL\n",
    "\n",
    "# Visualizations: volcano plot, number of regulated proteins per FDR, interactive table?\n",
    "for (i in 1:ncol(plvalues)) {\n",
    "    hist(plvalues[,i],100,border=NA,col=\"#555555\", main=paste(\"p-value distribution\\nComparison\",colnames(fcs)[i], sep=\"\\n\"),\n",
    "        xlab=\"p-values\")\n",
    "    plot(fcs[,i], -log10(qlvalues[,i]),pch=16,col=\"#44FFFF99\",\n",
    "        xlab=\"log(fold-change)\", ylab=\"-log10(FDR)\", main=paste(\"Volcano plot\\nComparison\",\n",
    "                                                                colnames(fcs)[i], sep=\"\\n\"),\n",
    "        ylim=c(0,max(2,max(-log10(qlvalues[,i])))))\n",
    "    abline(h=-log10(c(0.001,0.01,0.05)), col=2:4,lwd=2)\n",
    "    text(c(0,0,0), c(3,2,1.3),c(\"FDR=0.001\",\"FDR=0.01\",\"FDR=0.05\"),pos=1)\n",
    "    ddd <- c(0.0001,sort(qlvalues[,i]))\n",
    "plot(ddd, 0:(length(ddd)-1),type=\"l\",xlim=c(1e-3,1),log=\"x\", main=paste(\"Significant protein versus FDR\\nComparison\",colnames(fcs)[i], sep=\"\\n\")) \n",
    "    abline(v=c(0.001,0.01,0.05), col=2:4, xlab=\"FDR\", ylab=\"Number of proteins\")\n",
    "    \n",
    "}\n",
    "\n",
    "# How far should we go? Clustering (when having more then 2 groups)? \n",
    "# Hierarchical clustering of significant features? clusterProfiler?\n",
    "\n",
    "\n",
    "# Saving stats\n",
    "statOut <- cbind(fcs, plvalues, qlvalues)\n",
    "colnames(statOut) <- paste(rep(c(\"log(fold-change)\",\"p-values\",\"q-values\"), each=ncol(plvalues)), colnames(statOut))\n",
    "statOut <- cbind(Proteins=rownames(fcs),statOut)\n",
    "print(head(statOut))\n",
    "write.csv(statOut, \"/home/biodocker/OUT/DifferentiallyRegulatedProteins.csv\",row.names=F)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:53:52.861990Z",
     "start_time": "2018-05-10T14:53:52.092468Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# test ground for interactive apps\n",
    "library(plotly)\n",
    "library(reshape)\n",
    "\n",
    "#print(head(melt(allProts)))\n",
    "\n",
    "x <- rnorm(1000)\n",
    "y <- rchisq(1000, df = 1, ncp = 0)\n",
    "group <- sample(LETTERS[1:5], size = 1000, replace = T)\n",
    "size <- sample(1:5, size = 1000, replace = T)\n",
    "\n",
    "ds <- data.frame(x, y, group, size)\n",
    "\n",
    "p <- plot_ly(ds, x = x, y = y, mode = \"markers\", split = group, size = size) %>%\n",
    "  layout(title = \"Scatter Plot\")\n",
    "embed_notebook(p)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T08:59:59.347465Z",
     "start_time": "2018-05-10T08:59:59.335751Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:38:27.204016Z",
     "start_time": "2018-05-10T14:38:27.136782Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "ddd <- sort(qlvalues[,1])\n",
    "plot(ddd, 1:length(ddd),type=\"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T09:14:03.702860Z",
     "start_time": "2018-05-10T09:14:03.696724Z"
    }
   },
   "outputs": [],
   "source": [
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
