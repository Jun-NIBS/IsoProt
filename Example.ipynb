{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# Protocol for analysis of labeled proteomics data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This jupyter notebook contains a complete workflow to process and quantify TMT and iTRAQ labelled MS/MS data. The analysis ranges from peak lists to differentially regulated proteins. The protocol can be adapted to different experimental designs, different search parameters and several protein quantification methods. \n",
    "The protocol is portable and reproducible, and should function on every computer that runs [Docker](docker.com).\n",
    "\n",
    "\n",
    "## Usage\n",
    "\n",
    "**To run the example**, scroll down, press the *Enter design* button and follow the further steps. Running the database search and quantification can take a few minutes.\n",
    "\n",
    "**To analyze your own data**\n",
    "\n",
    "1. Convert raw MS data to MGF files (PeptideShaker currently requires all input files to be in the MGF format). We recommend [ProteoWizard](http://proteowizard.sourceforge.net/).\n",
    "\n",
    "2. Use the \"Home\" screen of the Jupyter environment (normally at http://0.0.0.0:8888), navigate to the `IN` (delete iTRAQCancer.mgf before) or `data` directory and copy all MGF files there (using the `Upload` button)\n",
    "\n",
    "3. Scroll down in this document until you reach the `Workflow` section to start processing your data.\n",
    "\n",
    "4. All data files will be written to the folder **OUT**\n",
    "\n",
    "\n",
    "## Maintainer\n",
    "\n",
    "  * Veit Schwammle (veits@bmb.sdu.dk)\n",
    "  * Johannes Griss (johannes.griss@meduniwien.ac.at)\n",
    "  * Goran Vinterhalter\n",
    "\n",
    "## Software\n",
    "\n",
    "Database searches are performed using [searchGUI](https://github.com/compomics/searchgui) and the subsequent search results are filtered using [PeptideShaker](https://github.com/compomics/peptide-shaker). Down-stream data processing in [R](https://www.r-project.org/) used the [Bioconductor](https://bioconductor.org) libraries [MSnbase](https://bioconductor.org/packages/release/bioc/html/MSnbase.html) and [LIMMA](https://bioconductor.org/packages/release/bioc/html/limma.html) amongst others. \n",
    "\n",
    "\n",
    "[bio.tools](https://bio.tools) links for more detailed information about the used software:  \n",
    "https://bio.tools/searchgui  \n",
    "https://bio.tools/peptideshaker  \n",
    "https://bio.tools/msnbase  \n",
    "https://bio.tools/limma  \n",
    "\n",
    "\n",
    "\n",
    "## Diagram\n",
    "\n",
    "Provide a simple diagram of functionality of the workflow/software. We recommend using controlled vocabularies for input/output data types and file formats as well as provided operation of the tool(s). You can use http://edamontology.org terms for the description.\n",
    "\n",
    "__TODO: example__\n",
    "\n",
    "## System requirements\n",
    "\n",
    "Fill in the following items:\n",
    "Required hard disk space for docker image, input and output files: \n",
    "You will need space for your raw files and files from the down-stream analysis (mostly < 1 GB)\n",
    "\n",
    "Required memory: Recommend min. 4 GB or RAM\n",
    "\n",
    "Recommmended number of threads: 4-8\n",
    "\n",
    "## Example \n",
    "\n",
    "The example data file is an extract of spectra from the iTRAQ 8-plex data in ref. https://doi.org/10.1371/journal.pone.0137048\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# Workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T06:23:33.217811Z",
     "start_time": "2018-07-13T06:23:31.476112Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false,
    "hide_input": true,
    "init_cell": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "### Specify parameters for database search and evaluation of identified peptide-spectrum matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T06:23:34.238126Z",
     "start_time": "2018-07-13T06:23:33.226843Z"
    },
    "code_folding": [],
    "hideCode": true,
    "hidePrompt": true,
    "hide_input": true,
    "init_cell": true,
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>Folders and files</h4>'), Label(value='Fasta file (database, must NOT contain dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell contains the complete code to\n",
    "# 1.) Display the GUI for the user to enter the search parameters\n",
    "# 2.) Launch the search based on these parameters\n",
    "# 3.) Display a button once the search is complete to execute the subsequent R analysis code\n",
    "\n",
    "search_in = None\n",
    "\n",
    "def complete_function():\n",
    "    global search_in\n",
    "    \n",
    "    search_in = search_ui_out\n",
    "    search_in[\"on_search_complete\"] = search_complete\n",
    "    %run \"Scripts/search.ipy\"\n",
    "    \n",
    "def search_complete():\n",
    "    global btn_next_cell_in\n",
    "    \n",
    "    # Display a button to execute the next R cell(s)\n",
    "    btn_next_cell_in = {\"description\": \"Run R analysis\", \"n_cells_to_run\": 11}\n",
    "    %run \"Scripts/btn_next_cell.ipy\"\n",
    "\n",
    "search_ui_in = {\"on_complete_description\": \"Run my search\", \"on_complete_function\": complete_function}\n",
    "\n",
    "%run \"Scripts/search_ui.ipy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Search Settings into R Objects\n",
    "\n",
    "These cells should not produce any output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T09:28:03.469623Z",
     "start_time": "2018-07-11T09:28:03.463944Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# Since py2ri cannot convert dict objects, simply save everything R needs as a JSON string\n",
    "\n",
    "# remove the callback function first\n",
    "search_in.pop(\"on_search_complete\", None)\n",
    "\n",
    "import json\n",
    "search_in_string = json.dumps(search_in)\n",
    "search_out_string = json.dumps(search_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T09:28:03.487437Z",
     "start_time": "2018-07-11T09:28:03.477167Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%%R -i search_in_string,search_out_string\n",
    "# Convert the JSON objects back into \"natural\" R objects\n",
    "suppressWarnings(library(rjson))\n",
    "\n",
    "search_in = fromJSON(search_in_string, simplify = T)\n",
    "search_out = fromJSON(search_out_string, simplify = T)\n",
    "\n",
    "# load the experimental design\n",
    "ExpDesign <- read.table(search_in[\"exp_design_file\"][[1]],sep=\"\\t\",header=T)\n",
    "\n",
    "rm(search_in_string, search_out_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Quantify Spectra at the peptide level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T09:28:31.514710Z",
     "start_time": "2018-07-11T09:28:03.490749Z"
    },
    "code_folding": [
     74
    ],
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%R --width=1000\n",
    "\n",
    "print(\"Processing identification data...\")\n",
    "\n",
    "\n",
    "## assuming that the computer allows min. 4 threads\n",
    "NumThreads <- 4\n",
    "\n",
    "# library causes the execution to fail if the library is missing\n",
    "suppressWarnings(suppressMessages(library(lattice)))\n",
    "suppressWarnings(suppressMessages(library(stringr)))\n",
    "suppressWarnings(suppressMessages(library(mzID)))\n",
    "suppressWarnings(suppressMessages(library(MSnbase)))\n",
    "\n",
    "# warnings as stdout\n",
    "sink(stdout(), type = \"message\")\n",
    "\n",
    "# change to the input directory\n",
    "spectradirs <- unlist(search_in[\"input_directory\"])\n",
    "out_dir <- search_in[\"workdir\"][[1]]\n",
    "#setwd(out_dir)\n",
    "\n",
    "## Folder names for different runs (e.g. different replicates, ...)\n",
    "samples <- unique(ExpDesign$spec_dir)\n",
    "\n",
    "# If only one folder, then set correct folder names\n",
    "if(length(samples) == 1) {\n",
    "    samples <- \"./\"\n",
    "    ExpDesign$spec_dir <- \"./\"\n",
    "}\n",
    "sampledirs <- paste(out_dir,\"/\",samples,sep=\"\")\n",
    "all_ident_files <- search_out[[1]]\n",
    "if (length(sampledirs) != length(spectradirs) | length(sampledirs) != length(all_ident_files)) {\n",
    "    stop(\"Unequal number of sample folders\")\n",
    "}\n",
    "names(sampledirs) <- names(spectradirs) <- names(all_ident_files) <- samples\n",
    "\n",
    "print(all_ident_files)\n",
    "print(sampledirs)\n",
    "print(spectradirs)\n",
    "\n",
    "\n",
    "PSMDat <- PepDat <- ProtDat <- list()\n",
    "for (s in samples) {\n",
    "    ## Organize technical runs in the same folder\n",
    "    # filenames\n",
    "    print(paste(\"Processing files from folder\",s))\n",
    "    \n",
    "    ident_files <- all_ident_files[s]\n",
    "    mgf_files <- list.files(spectradirs[s],pattern=\"mgf.filtered$\",full.names = T)\n",
    "    \n",
    "    print(mgf_files)\n",
    "  \n",
    "    # make sure all input files exist\n",
    "    if (is.null(ident_files)) {\n",
    "        stop(\"Error: No identification files\")\n",
    "    }\n",
    "    if (is.null(mgf_files)) {\n",
    "        stop(\"Error: No spectrum files\")\n",
    "    }\n",
    "    if (!file.exists(ident_files)) {\n",
    "        stop(\"Error: Cannot find identification files \", ident_files)\n",
    "    }\n",
    "    for (mgf_file in mgf_files) {\n",
    "        if (!file.exists(mgf_file)) {\n",
    "            stop(\"Error: Cannot find mgf file \", mgf_file)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # ---- load the PSMs ----\n",
    "    max.fdr <- search_in[\"target_fdr\"]\n",
    "    psms <- read.csv(ident_files, sep = \"\\t\",stringsAsFactors = F)\n",
    "  \n",
    "    if (! \"Decoy\" %in% names(psms)) {\n",
    "        stop(\"Error: No decoy information available in output file\")\n",
    "    }\n",
    "  \n",
    "    print(paste(\"Loaded\",nrow(psms), \"PSMs\"))\n",
    "  \n",
    "    # ---- Confidence filter ----\n",
    "    # TODO: This could be replaced by the PeptideShaker functionality\n",
    "    psms <- psms[order(psms[, \"Confidence....\"], decreasing = T), ]\n",
    "    decoy.psms <- which(psms[, \"Decoy\"] == \"1\")\n",
    "  \n",
    "    decoy.count <- 0\n",
    "  \n",
    "    for (decoy.index in decoy.psms) {\n",
    "        decoy.count <- decoy.count + 1\n",
    "        target.count <- decoy.index - decoy.count\n",
    "        cur.fdr <- (decoy.count * 2) / (decoy.count + target.count)\n",
    "    \n",
    "        if (cur.fdr > max.fdr) {\n",
    "          # filter\n",
    "          psms <- psms[1:decoy.index - 1,]\n",
    "          break\n",
    "        }\n",
    "    }\n",
    "  \n",
    "    print(paste0(\"Filtered \", nrow(psms), \" PSMs @ \", max.fdr, \" FDR\"))\n",
    "    \n",
    "    if (nrow(psms) < 1) {\n",
    "        stop(\"Error: No valid PSMs found\")\n",
    "    }\n",
    "    \n",
    "    # ---- prepare for MSnbase ----\n",
    "    psms$rank <- 1\n",
    "    psms$desc <- psms$Protein.s.\n",
    "    psms$spectrumID <- psms$Spectrum.Title #str_extract(psms$Spectrum.Title, \"scan=[0-9]*\")\n",
    "    psms$spectrumFile <- psms$Spectrum.File\n",
    "    psms$idFile <- ident_files\n",
    "    # remove unnecessary PTMs from modified sequence\n",
    "    # TODO: define whether to take oxidation, ...\n",
    "    psms$Modified.Sequence <- gsub(\"<cmm>\",\"\",psms$Modified.Sequence)\n",
    "    psms$Modified.Sequence <- sub(\"[a-z,A-Z]*-\",\"\",psms$Modified.Sequence)\n",
    "    psms$Modified.Sequence <- sub(\"-[a-z,A-Z]*\",\"\",psms$Modified.Sequence)\n",
    "    psms$Modified.Sequence <- gsub(\"<iTRAQ>\",\"\",psms$Modified.Sequence)\n",
    "    psms$Modified.Sequence <- gsub(\"<TMT>\",\"\",psms$Modified.Sequence)\n",
    "    psms$sequence <- psms$Modified.Sequence\n",
    "    # Optional:\n",
    "    # psms$Modified.Sequence <- gsub(\"<ox>\",\"\",psms$Modified.Sequence)\n",
    "  \n",
    "    # --- Load the spectra ----\n",
    "    allSpectra <- list()\n",
    "    for (mgf_file in mgf_files) {\n",
    "        myExp1 <- readMgfData(mgf_file, verbose=T)\n",
    "    \n",
    "        for (i in 1:ncol(fData(myExp1))) {\n",
    "          if (is.factor(fData(myExp1)[,i]))\n",
    "            fData(myExp1)[,i] <- as.character(fData(myExp1)[,i])\n",
    "        }\n",
    "        fData(myExp1)$spectrumFile <- mgf_file\n",
    "        allSpectra[[mgf_file]] <- myExp1\n",
    "    }\n",
    "    \n",
    "    # ---- merge identification and spectra data and run the quantification ----\n",
    "    # get the MSnbase quantification object\n",
    "    known.methods <- c(\"TMT10\",\"TMT6\",\"iTRAQ4\",\"iTRAQ8\",\"iTRAQ4\", \"iTRAQ8\")\n",
    "    selected.method <- gsub(\" \\\\(.*\", \"\", search_in[\"labelling_method\"][[1]])\n",
    "    \n",
    "    if (!selected.method %in% known.methods) {\n",
    "        stop(\"Error: Labelling method not supported\")\n",
    "    }\n",
    "    \n",
    "    quant.method <- get(selected.method)\n",
    "    \n",
    "    # run the merging and quantification in paralell\n",
    "    cl <- makeCluster(NumThreads)\n",
    "    myExp <- qnt <- list()\n",
    "    for (mgf_file in mgf_files) {\n",
    "        myExp[[mgf_file]] <- addIdentificationData(\n",
    "            allSpectra[[mgf_file]],\n",
    "            psms,\n",
    "            decoy=\"Decoy\",\n",
    "            rank=\"rank\",\n",
    "            acc=\"Protein.s.\",\n",
    "            icol=\"Spectrum.Title\",\n",
    "            fcol=\"TITLE\",\n",
    "            desc=\"desc\",\n",
    "            pepseq=\"Modified.Sequence\",\n",
    "            verbose=T)\n",
    "        # print(idSummary(myExp[[mgf_file]]))\n",
    "        \n",
    "        # remove all unidentified spectra\n",
    "        myExp[[mgf_file]] <- removeNoId(myExp[[mgf_file]])\n",
    "        \n",
    "        # quantify everything\n",
    "        qnt[[mgf_file]] <- quantify(myExp[[mgf_file]], \n",
    "                                    method = \"sum\", \n",
    "                                    reporters = quant.method, \n",
    "                                    strict = F, verbose = T )\n",
    "      \n",
    "        # Plot reporter QC\n",
    "        hist(unlist(mz(myExp[[mgf_file]])), 1000, main=paste(\"m/z accuracy of reporter ions\\n\",mgf_file), \n",
    "            xlim=range(quant.method@mz)+c(-1,1),xlab=\"m/z\",col=\"#666666\",border=NA)\n",
    "        abline(v=quant.method@mz,col=2,lwd=0.5)\n",
    "    } \n",
    "    \n",
    "    stopCluster(cl)\n",
    "    \n",
    "    # ---- run the impurity correction ----\n",
    "    imp <- makeImpuritiesMatrix(length(quant.method),edit=F)\n",
    "    for (i in 1:length(qnt)) {\n",
    "        qnt[[i]] <- purityCorrect(qnt[[i]],imp)\n",
    "        exprs(qnt[[i]]) <- log2(exprs(qnt[[i]]))\n",
    "        qnt[[i]] <- normalise(qnt[[i]],\"center.median\")\n",
    "        qnt[[i]] <- updateFeatureNames(qnt[[i]],label = paste(\"Sample\",i))\n",
    "    }\n",
    "    \n",
    "    # ---- combine the quantification data ----\n",
    "    names(qnt) <- NULL\n",
    "    allqnt <- do.call(\"combine\",args=qnt)\n",
    "    allqnt <- filterNA(allqnt, pNA=0.5)\n",
    "\n",
    "    # ---- add the sample annotations ----\n",
    "    SampleExpDesign <- ExpDesign[ExpDesign$spec_dir == s,]\n",
    "    if (nrow(SampleExpDesign) != nrow(pData(allqnt))) {\n",
    "        stop(\"Error: Experimental design does not fit the number of quantified samples.\")\n",
    "    }\n",
    "\n",
    "    # merge the annotations\n",
    "    pdata.org <- pData(allqnt)\n",
    "    pdata.combined <- merge(pdata.org, SampleExpDesign, all.x = T, all.y = F, by.x = 0, by.y = \"channel\")\n",
    "    rownames(pdata.combined) <- pdata.combined[, \"Row.names\"]\n",
    "    pdata.combined$Row.names <- NULL\n",
    "\n",
    "    # save\n",
    "    pData(allqnt) <- pdata.combined[colnames(allqnt), ]\n",
    "  \n",
    "    ## Setting the stage for the iPQF inference method\n",
    "    names(fData(allqnt))[which(names(fData(allqnt))==\"Protein.s.\")] <- \"accession\"\n",
    "    names(fData(allqnt))[which(names(fData(allqnt))==\"Variable.Modifications\")] <- \"modifications\"\n",
    "    names(fData(allqnt))[which(names(fData(allqnt))==\"m.z\")] <- \"mass_to_charge\"\n",
    "    names(fData(allqnt))[which(names(fData(allqnt))==\"Confidence....\")] <- \"search_engine_score\"\n",
    "    \n",
    "    \n",
    "    write.csv(exprs(allqnt),paste(sampledirs[s],\"/AllQuantPSMs.csv\",sep=\"\"))  \n",
    "    save(allqnt, file=paste(sampledirs[s],\"/AllQuantPSMs.RData\",sep=\"\") )\n",
    "    \n",
    "    PSMDat[[s]] <- allqnt \n",
    "}    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T09:28:32.477600Z",
     "start_time": "2018-07-11T09:28:31.517167Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%%R --width 800\n",
    "\n",
    "\n",
    "suppressWarnings(suppressMessages(library(plotly)))\n",
    "suppressWarnings(suppressMessages(library(reshape)))\n",
    "\n",
    "\n",
    "panel.cor <- function(x, y, digits=2, prefix=\"\", cex.cor, ...) \n",
    "{\n",
    "    usr <- par(\"usr\"); on.exit(par(usr)) \n",
    "    par(usr = c(0, 1, 0, 1)) \n",
    "    r <- abs(cor(x, y, use=\"na.or.complete\")) \n",
    "    txt <- format(c(r, 0.123456789), digits=digits)[1] \n",
    "    txt <- paste(prefix, txt, sep=\"\") \n",
    "    cex.cor <- 0.8/strwidth(txt) \n",
    "    test <- cor.test(x,y) \n",
    "    # borrowed from printCoefmat\n",
    "    Signif <- symnum(test$p.value, corr = FALSE, na = FALSE, \n",
    "                  cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),\n",
    "                  symbols = c(\"***\", \"**\", \"*\", \".\", \" \")) \n",
    " \n",
    "    text(0.5, 0.5, txt, cex = cex.cor * r) \n",
    "}\n",
    "\n",
    "panel.hist <- function(x, hist.col=\"#993333\", ...)\n",
    "{\n",
    "    usr <- par(\"usr\"); on.exit(par(usr))\n",
    "   par(usr = c(usr[1:2], 0, 1.5) )\n",
    "    h <- hist(x, plot = FALSE, border=NA,breaks=50)\n",
    "    breaks <- h$breaks; nB <- length(breaks)\n",
    "  y <- h$counts; y <- y/max(y)\n",
    "    rect(breaks[-nB], 0, breaks[-1], y,col=hist.col,border=NA)\n",
    "}\n",
    "\n",
    "condNames <- list()\n",
    "for (s in samples) {\n",
    "    allqnt <- PSMDat[[s]]\n",
    "    \n",
    "    condNames[[s]] <- ExpDesign[ExpDesign$spec_dir == s,\"sample_orig\"]\n",
    "    conditions <- condNames[[s]]\n",
    "    if (sampledirs[s] != \"\")\n",
    "    condNames[[s]] <- paste(\"Sample\", 1:length(conditions), condNames[[s]], s, sep=\"\\n\")\n",
    "    pData(allqnt)$sample_name <- paste(condNames[[s]], sampledirs[s])\n",
    "    pData(allqnt)$sample_group <- condNames[[s]]\n",
    "    \n",
    "    \n",
    "    ## QC Plots\n",
    "  #boxplot(exprs(allqnt), main =paste(\"Sample\",s), labels =  condNames)\n",
    "    \n",
    "    \n",
    "       conditionsPlot <- rep(conditions, each=nrow(exprs(allqnt)))\n",
    "    p <- ggplot(melt(exprs(allqnt)), aes(x=X2, y=value, fill=conditionsPlot)) + geom_violin(trim=FALSE) + \n",
    "    geom_boxplot(width=0.1) + theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n",
    "    xlab(\"\") + ylab(\"PSM expression\") + ggtitle(paste(\"Distributions in run\",s))\n",
    "    print(p)\n",
    "        par(mfrow=c(1,3))\n",
    "    hist(fData(allqnt)$npsm.pep,xlab=\"Number of PSMs per peptide\",100,border=0,col=\"#AA4444\", main=\"PSM distribution (peptides)\")\n",
    "    hist(fData(allqnt)$npep.prot,xlab=\"Number of PSMs per protein\",100,border=0,col=\"#44AA44\", main=\"PSM distribution (proteins)\")\n",
    "    hist(fData(allqnt)$npsm.prot,xlab=\"Number of peptides per protein\",100,border=0,col=\"#4444AA\", main=\"Peptide distribution\")\n",
    "\n",
    "    par(mfrow=c(1,1))\n",
    "    \n",
    "    \n",
    "  pairs(exprs(allqnt),lower.panel=panel.smooth, upper.panel=panel.cor, diag.panel=panel.hist, main = paste(\"MS run\",s),\n",
    "cex=0.1,col=\"#33333388\",pch=15, labels =  condNames[[s]])\n",
    "    \n",
    "    PSMDat[[s]] <- allqnt\n",
    "    \n",
    "    \n",
    "  #print(fData(allqnt))  \n",
    "}\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protein Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T09:28:33.331929Z",
     "start_time": "2018-07-11T09:28:32.480403Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%%R --width 800\n",
    "\n",
    "####### TODO: implement considering PTMs (or not)\n",
    "\n",
    "for (s in samples) {\n",
    "    load(paste(sampledirs[s],\"/AllQuantPSMs.RData\",sep=\"\"))\n",
    "\n",
    "    print(paste(\"Files from\",s))\n",
    "    \n",
    "    allqnt <- PSMDat[[s]]\n",
    "    \n",
    "    #print(colnames(fData(allqnt)))\n",
    "    \n",
    "    # get the selected method\n",
    "    summarization.function <- search_in[\"summarization_method\"][[1]]\n",
    "    #summarization.function <- \"median\"\n",
    "    \n",
    "    # get minimum peptides\n",
    "    min_peps <- search_in[\"min_protein_psms\"][[1]]\n",
    "    \n",
    "    \n",
    "    print(paste(\"Using \",summarization.function,\"for summarization to proteins ...\"))\n",
    "\n",
    "    # keep only PSMs with at least 50% coverage over samples\n",
    "    \n",
    "    allProts <- NULL\n",
    "    # remove missing values for iPQF\n",
    "    if(summarization.function == \"iPQF\") {\n",
    "        exprs(allqnt) <- 2^exprs(allqnt)\n",
    "        # remove all spectra with missing values\n",
    "        has.missing.values <- (rowSums(is.na(exprs(allqnt))) > 0 | rowSums(exprs(allqnt) == 0)) > 0    \n",
    "        print(paste0(\"Removing \", sum(has.missing.values), \" PSMs with missing values for quantification\"))\n",
    "        allqnt <- filterNA(allqnt,0.0)\n",
    "           \n",
    "        # filter for minimal peptide number\n",
    "    has_too_few_peps <- fData(allqnt)$npep.prot < min_peps\n",
    "    num_prot_rm <- length(unique(fData(allqnt)[has_too_few_peps, \"accession\"]))\n",
    "    print(paste(\"Removing\",sum(has_too_few_peps),\"PSMs corresponding to\",num_prot_rm,\"proteins with less then\",min_peps,\"peptides\"))\n",
    "\n",
    "        allProts <- combineFeatures(allqnt, \n",
    "                                groupBy=fData(allqnt)$accession, \n",
    "                                verbose=F)\n",
    "        exprs(allProts) <- log2(exprs(allProts))\n",
    "    } else {\n",
    "    \n",
    "        # remove all spectra with missing values\n",
    "        has.missing.values <- rowSums(is.na(exprs(allqnt)) | rowSums(exprs(allqnt) == 0, na.rm=T)) > ncol(allqnt)*0.5    \n",
    "        print(paste0(\"Removing \", sum(has.missing.values), \" PSMs with more than 50% missing values for quantification\"))\n",
    "        allqnt <- allqnt[!has.missing.values, ]\n",
    "\n",
    "                # filter for minimal peptide number\n",
    "    has_too_few_peps <- fData(allqnt)$npep.prot < min_peps\n",
    "    num_prot_rm <- length(unique(fData(allqnt)[has_too_few_peps, \"accession\"]))\n",
    "    print(paste(\"Removing\",sum(has_too_few_peps),\"PSMs corresponding to\",num_prot_rm,\"proteins with less then\",min_peps,\"peptides\"))\n",
    "\n",
    "        allProts <- combineFeatures(allqnt, na.rm=T,\n",
    "                                groupBy=fData(allqnt)$accession, \n",
    "                                verbose=F)\n",
    "    }\n",
    " \n",
    "    # create a plot of all protein expression values\n",
    "    p <- ggplot(melt(exprs(allProts)), aes(x=X2, y=value, fill=rep(conditions,each=nrow(exprs(allProts))))) + \n",
    "            geom_violin(trim=FALSE) + \n",
    "            geom_boxplot(width=0.1) +\n",
    "            theme_classic() + \n",
    "            theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n",
    "            xlab(\"\") + \n",
    "            ylab(\"Protein expression\")\n",
    "\n",
    "    # display the plot\n",
    "    print(p)\n",
    "\n",
    "    # save the expression values\n",
    "    write.exprs(allProts,file=paste(sampledirs[s],\"/AllQuantProteins.csv\",sep=\"\"))\n",
    "  \n",
    "    ProtDat[[s]] <- allProts <- exprs(allProts)\n",
    "    colnames(ProtDat[[s]]) <- condNames[[s]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample similarity and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T09:28:33.506870Z",
     "start_time": "2018-07-11T09:28:33.334565Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%%R --width 1000 --height 600\n",
    "\n",
    "\n",
    "par(mfrow=c(1,1))\n",
    "\n",
    "# Adjust each protein of each MS run by the mean of their expressions over the channels\n",
    "# TODO: option for other adjustments (e.g. to pool)?\n",
    "for (s in samples) {\n",
    "    ProtDat[[s]] <- ProtDat[[s]] - rowMeans(ProtDat[[s]],na.rm=T)\n",
    "}\n",
    "\n",
    "\n",
    "# Merge different samples\n",
    "    totProts <- ProtDat[[1]]\n",
    "if (length(samples)>1) {\n",
    "    print(\"Merging samples (if needed) ...\")\n",
    "    totProts <- data.frame(rownames(totProts),totProts)\n",
    "    for (s in samples[2:length(samples)])\n",
    "        totProts <- merge(totProts,ProtDat[[s]], all=T, by.x=1, by.y=0)\n",
    "    rownames(totProts) <- totProts[,1]\n",
    "    totProts <- totProts[,2:ncol(totProts)]\n",
    "} \n",
    "\n",
    "\n",
    "write.csv(totProts,file=paste(out_dir,\"/AllQuantProteinsInAllSamples.csv\",sep=\"\"))\n",
    "\n",
    "# PCA\n",
    "  pca <- princomp((totProts[complete.cases((totProts)),]))\n",
    "  #plot(pca)\n",
    "  plot(pca$loadings, cex=2, pch=16, col=as.numeric(as.factor(ExpDesign[[\"sample_orig\"]])))\n",
    "  text(pca$loadings,colnames(totProts), pos=2)\n",
    "    \n",
    "  print(paste(\"Quantified a total of\",nrow(allProts),\"protein groups\"))\n",
    "\n",
    "\n",
    "\n",
    "##Statistics\n",
    "library(limma)\n",
    "library(qvalue)\n",
    "NumCond <- length(unique(ExpDesign$sample_orig))\n",
    "  if (NumCond < 2)\n",
    "      stop(\"Only 1 experimental condition -> no statistics\")\n",
    "\n",
    "design <- model.matrix(~0+factor(ExpDesign$sample_group)-1)\n",
    "  colnames(design)<-make.names(paste(unique(ExpDesign$sample_orig),sep=\"\"))\n",
    "  contrasts<-NULL\n",
    "  First <- 1\n",
    "  for (i in (1:NumCond)[-First]) contrasts<-append(contrasts,paste(colnames(design)[i],\"-\",colnames(design)[First],sep=\"\"))\n",
    "  print(paste(\"Statistical tests carried out to compare:\",contrasts))\n",
    "  contrast.matrix<-makeContrasts(contrasts=contrasts,levels=design)\n",
    "  # print(dim(Data))\n",
    "  lm.fitted <- lmFit(totProts,design)\n",
    "  lm.contr <- contrasts.fit(lm.fitted,contrast.matrix)\n",
    "  lm.bayes <- eBayes(lm.contr)\n",
    "  #topTable(lm.bayes)\n",
    " plvalues <- lm.bayes$p.value\n",
    "fcs <- lm.bayes$coefficients\n",
    "  qlvalues <- matrix(NA,nrow=nrow(plvalues),ncol=ncol(plvalues),dimnames=dimnames(plvalues))\n",
    "  # qvalue correction\n",
    " for (i in 1:ncol(plvalues)) {\n",
    "    tqs <- qvalue(na.omit(plvalues[,i]))$qvalues\n",
    "    qlvalues[names(tqs),i] <- tqs\n",
    "  }\n",
    "  \n",
    "\n",
    "par(mfrow=c(1,3))\n",
    "\n",
    "statTable <- NULL\n",
    "\n",
    "# Visualizations: volcano plot, number of regulated proteins per FDR, interactive table?\n",
    "for (i in 1:ncol(plvalues)) {\n",
    "    hist(plvalues[,i],100,border=NA,col=\"#555555\", main=paste(\"p-value distribution\\nComparison\",colnames(fcs)[i], sep=\"\\n\"),\n",
    "        xlab=\"p-values\")\n",
    "    plot(fcs[,i], -log10(qlvalues[,i]),pch=16,col=\"#44FFFF99\",\n",
    "        xlab=\"log(fold-change)\", ylab=\"-log10(FDR)\", main=paste(\"Volcano plot\\nComparison\",\n",
    "                                                                colnames(fcs)[i], sep=\"\\n\"),\n",
    "        ylim=c(0,max(2,max(-log10(qlvalues[,i]), na.rm=T))))\n",
    "    abline(h=-log10(c(0.001,0.01,0.05)), col=2:4,lwd=2)\n",
    "    text(c(0,0,0), c(3,2,1.3),c(\"FDR=0.001\",\"FDR=0.01\",\"FDR=0.05\"),pos=1)\n",
    "    ddd <- c(0.0001,sort(qlvalues[,i]))\n",
    "plot(ddd, 0:(length(ddd)-1),type=\"l\",xlim=c(1e-3,1),log=\"x\", main=paste(\"Significant protein versus FDR\\nComparison\",colnames(fcs)[i], sep=\"\\n\")) \n",
    "    abline(v=c(0.001,0.01,0.05), col=2:4, xlab=\"FDR\", ylab=\"Number of proteins\")\n",
    "    \n",
    "}\n",
    "\n",
    "# How far should we go? Clustering (when having more then 2 groups)? \n",
    "# Hierarchical clustering of significant features? clusterProfiler?\n",
    "\n",
    "\n",
    "# Saving stats\n",
    "statOut <- cbind(fcs, plvalues, qlvalues)\n",
    "colnames(statOut) <- paste(rep(c(\"log(fold-change)\",\"p-values\",\"q-values\"), each=ncol(plvalues)), colnames(statOut))\n",
    "statOut <- cbind(Proteins=rownames(fcs),statOut)\n",
    "#print(head(statOut))\n",
    "write.csv(statOut, \"/home/biodocker/OUT/DifferentiallyRegulatedProteins.csv\",row.names=F)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run your own script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T09:30:01.602223Z",
     "start_time": "2018-07-11T09:30:01.568156Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "\n",
    "# totProts is a table with all quantifications\n",
    "boxplot(totProts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T20:26:58.306203Z",
     "start_time": "2018-07-09T20:26:55.843688Z"
    },
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# test ground for interactive apps\n",
    "library(plotly)\n",
    "library(reshape)\n",
    "\n",
    "#print(head(melt(allProts)))\n",
    "\n",
    "x <- rnorm(1000)\n",
    "y <- rchisq(1000, df = 1, ncp = 0)\n",
    "group <- sample(LETTERS[1:5], size = 1000, replace = T)\n",
    "size <- sample(1:5, size = 1000, replace = T)\n",
    "\n",
    "ds <- data.frame(x, y, group, size)\n",
    "\n",
    "p <- plot_ly(ds, x = x, y = y, mode = \"markers\", split = group, size = size) %>%\n",
    "  layout(title = \"Scatter Plot\")\n",
    "embed_notebook(p)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T05:10:03.860742Z",
     "start_time": "2018-07-12T05:10:03.854604Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
